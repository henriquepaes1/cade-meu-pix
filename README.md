# Twitter ETL Pipeline

Async ETL pipeline that processes Twitter data through an LLM and stores results in Supabase.

## Features

- âœ… **Async processing** with rate limiting using `asyncio.Semaphore`
- âœ… **Batch processing**: 20 items per LLM call
- âœ… **Concurrent requests**: Configurable rate limit (default: 5 concurrent)
- âœ… **Automatic retries**: 3 attempts with exponential backoff
- âœ… **Bulk database inserts**: Up to 1000 records per batch
- âœ… **Error handling**: Tracks failures without stopping the pipeline
- âœ… **Modular architecture**: Clean separation of concerns

## Project Structure

```
SundAI - ETL Twitter/
â”œâ”€â”€ config.py           # Configuration & constants
â”œâ”€â”€ llm_client.py       # LLM API logic (OpenRouter)
â”œâ”€â”€ db_client.py        # Database logic (Supabase)
â”œâ”€â”€ main.py             # Main orchestration
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ .env               # Environment variables (not in repo)
â””â”€â”€ README.md          # This file
```

## Setup

1. **Install dependencies**:
```bash
pip install -r requirements.txt
```

2. **Configure environment variables**:
```bash
# Copy the example file
cp .env.example .env

# Edit .env with your credentials
```

Required variables:
- `OPENROUTER_API_KEY`: Your OpenRouter API key
- `SUPABASE_URL`: Your Supabase project URL
- `SUPABASE_KEY`: Your Supabase anon/service key
- `SUPABASE_TABLE`: Table name (default: `processed_data`)

3. **Update the prompt**:
Edit the `PROMPT_TEMPLATE` in `config.py` with your actual prompt.

## Usage

### Option 1: Import and use in your code

```python
import asyncio
from main import run_pipeline

# Your Twitter data
input_data = [
    {
        "text": "Example tweet text",
        "username": "user123",
        "name": "John Doe",
        "location": "New York, NY"
    },
    # ... more items
]

# Run the pipeline
asyncio.run(run_pipeline(input_data))
```

### Option 2: Run the example directly

```bash
python main.py
```

## Configuration

Edit these constants in `config.py`:

```python
LLM_BATCH_SIZE = 20              # Items per LLM request
DB_BATCH_SIZE = 1000             # Records per DB insert
MAX_CONCURRENT_REQUESTS = 5      # Rate limit (concurrent API calls)
MAX_RETRIES = 3                  # Retry attempts for failed requests
```

## Module Documentation

### `config.py`
- Contains all configuration constants and environment variables
- Validates required environment variables with `validate_config()`

### `llm_client.py`
- Handles all OpenRouter API communication
- Implements async batch processing with Semaphore rate limiting
- Includes retry logic with exponential backoff

### `db_client.py`
- Manages Supabase database operations
- Performs bulk inserts in batches of up to 1000 records

### `main.py`
- Main orchestration - coordinates the entire pipeline
- Clean entry point for running the ETL process

## Pipeline Flow

```
Input Data (List of Dicts)
    â†“
Split into batches of 20
    â†“
Process concurrently with LLM (rate-limited to 5 concurrent)
    â†“
Collect all results
    â†“
Split into batches of 1000
    â†“
Save to Supabase
    â†“
Complete âœ“
```

## Error Handling

- **LLM failures**: Retried 3 times with exponential backoff
- **Failed batches**: Logged but don't stop the pipeline
- **DB failures**: Logged per batch, pipeline continues

## Example Output

```
============================================================
ðŸš€ Starting ETL Pipeline
============================================================

ðŸ“Š Processing 100 items in 5 batches of 20
ðŸ”’ Rate limit: 5 concurrent requests

âœ“ Batch 1 processed successfully
âœ“ Batch 2 processed successfully
âœ“ Batch 3 processed successfully
âœ“ Batch 4 processed successfully
âœ“ Batch 5 processed successfully

âœ“ Successfully processed: 5/5 batches

ðŸ’¾ Saving 5 results to Supabase...
âœ“ DB Batch 1: Saved 5 records

ðŸ’¾ Database Summary:
  âœ“ Saved: 5 records

============================================================
âœ… ETL Pipeline Complete
============================================================
```

